{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImitationLearning-Intent-V2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3j__1QFRpDhC"
      },
      "source": [
        "# Primitive Segmentation using ConvLSTM\n",
        "\n",
        "**Author:** Aditya Jain <br>\n",
        "**Date started:** 27th July, 2020<br>\n",
        "**Description:** Predict primitves actions in a human demonstration using ConvLSTM model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZFJSlMAbpDhE"
      },
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7gn6YDneJAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "72df09d3-2cd3-4d9c-9d3a-180301264f88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1_bJF4iepDhF",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "import os\n",
        "from glob import glob\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeqMeiJCzxTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_CLASSES  = 2          # no. of primitves in the TADL\n",
        "PX         = 128        # no. of rows in training/test images\n",
        "PY         = 128        # no. of columns in training/test images\n",
        "CHANNELS   = 3          # no. of channels in the image\n",
        "N_FRAMES   = 15         # no. of frames in each training/test video\n",
        "BATCH_SIZE = 32         # size of the batches\n",
        "DATA_DIR   = \"/content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL/\"\n",
        "TEST_SPLIT = 0.2        # no. of test samples to draw from data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkiq6-1Aejkz",
        "colab_type": "text"
      },
      "source": [
        "## Building the Dataset\n",
        "\n",
        "Reads the datafiles and builds the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBiC-UB6bPzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def video_path(dataset_dir):\n",
        "  '''\n",
        "  returns the paths of all video files in the dataset; takes input the parent directory\n",
        "  '''\n",
        "  # no. of primitives in the library\n",
        "  prim_actions    = [dI for dI in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir,dI))]\n",
        "  video_path_list = []\n",
        "  \n",
        "  # building a dictionary of primtive actions for label generation\n",
        "  prim_dict       = {}\n",
        "  i               = 0\n",
        "\n",
        "  for action in prim_actions:\n",
        "    prim_dict[action] = i\n",
        "    prim_path         = os.path.join(DATA_DIR, action)   # gives path for each primitive  \n",
        "    i                 += 1\n",
        "  \n",
        "    for video in os.listdir(prim_path):\n",
        "      video_path  = os.path.join(prim_path, video)        # path to all videos in a prim\n",
        "      video_path_list.append(video_path)\n",
        "      \n",
        "  return video_path_list, prim_dict\n",
        "\n",
        "\n",
        "video_list, primitives_dict = video_path(DATA_DIR)\n",
        "N_CLASSES                   = len(primitives_dict)\n",
        "\n",
        "\n",
        "def build_dataset(vid_list, primit_dict):\n",
        "    '''\n",
        "    This function builds the dataset given the video frames and no of primitives\n",
        "    '''\n",
        "\n",
        "    image_data  = []\n",
        "    label_data  = []\n",
        "\n",
        "    for video_path in vid_list:\n",
        "\n",
        "      label        = video_path.split(os.sep)[-2]\n",
        "      label        = primit_dict[label]\n",
        "      temp_image   = []\n",
        "      temp_label   = []\n",
        "    \n",
        "      for image in os.listdir(video_path):\n",
        "        image_path    = video_path + \"/\" + image \n",
        "      \n",
        "        # taking care of labels\n",
        "        # temp_label.append(label)\n",
        "\n",
        "        # Image read and processing\n",
        "        img = cv2.imread(image_path, 1)       # image read\n",
        "        img = cv2.resize(img, (PX, PY))       # image resize\n",
        "        # cv2_imshow(img)                     # optional command to visualize the read image\n",
        "        img = img.astype(\"float32\") / 255     # rescale the image from 0-1\n",
        "        temp_image.append(img)\n",
        "\n",
        "      image_data.append(temp_image)\n",
        "      temp_label = label       # temporary\n",
        "      label_data.append(temp_label)\n",
        "\n",
        "    # return image_data, label_data\n",
        "    return  np.asarray(image_data),  np.asarray(tf.one_hot(label_data, len(primit_dict)))\n",
        "\n",
        "data, label = build_dataset(video_list, primitives_dict)\n",
        "train_data, test_data, train_label, test_label = train_test_split(\n",
        "    data, label, test_size=0.20, shuffle=True, random_state=0)\n",
        "# dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label))\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8gcZ-1lkpDhK"
      },
      "source": [
        "## Build a model\n",
        "\n",
        "We create a model which take as input movies of shape\n",
        "`(n_frames, width, height, channels)` and returns a movie\n",
        "of identical shape.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD19WMc5yPHz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "618b05f8-8731-4509-b56a-44fd7f1b34d7"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape = (N_FRAMES, PX, PY, CHANNELS)),  \n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=False\n",
        "        ),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        # layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(N_CLASSES, activation='softmax'),\n",
        "        \n",
        "    ]\n",
        ")\n",
        "\n",
        "# print model summary\n",
        "model.summary()\n",
        "\n",
        "# model compilation\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_lst_m2d (ConvLSTM2D)    (None, 128, 128, 64)      154624    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 262144)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 262144)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 524290    \n",
            "=================================================================\n",
            "Total params: 678,914\n",
            "Trainable params: 678,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hM9IeKmypDhV"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-bBV_l6mpDhW",
        "colab": {}
      },
      "source": [
        "epochs = 20\n",
        "\n",
        "model.fit(\n",
        "    train_data,\n",
        "    train_label,\n",
        "    batch_size=2,\n",
        "    epochs=epochs,\n",
        "    verbose=2,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOno8JzfQJWd",
        "colab_type": "text"
      },
      "source": [
        "## Model Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pj6cJjHQNGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a32891b5-4bba-48e8-9d5f-5377a1b1f443"
      },
      "source": [
        "score = model.evaluate(test_data, test_label, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 99.90675354003906\n",
            "Test accuracy: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLnCLohPkYO9",
        "colab_type": "text"
      },
      "source": [
        "## Miscellaneous - Not to be run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WBHqG5W_Qou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.ConvLSTM2D(filters = 64, kernel_size = (3, 3), return_sequences = False, data_format = \"channels_last\", input_shape = (N_FRAMES, PX, PY, 3)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(2, activation = \"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ERnth0tmrLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape = (None, PX, PY, CHANNELS)),  \n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=False\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        \n",
        "        # layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(N_CLASSES, activation='softmax'),\n",
        "        \n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# model compilation\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cqcT5XrBDMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "61911d32-1f19-4fa5-80ab-5c227aa1d4a9"
      },
      "source": [
        "test_data = np.asarray(train_data)\n",
        "test_label = np.asarray(train_label)\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_label.shape)\n",
        "print(train_label)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 15, 128, 128, 3)\n",
            "(2, 2)\n",
            "[[1. 0.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}