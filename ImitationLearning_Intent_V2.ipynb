{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImitationLearning-Intent-V2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3j__1QFRpDhC"
      },
      "source": [
        "# Primitive Segmentation using ConvLSTM\n",
        "\n",
        "**Author:** Aditya Jain <br>\n",
        "**Date started:** 27th July, 2020<br>\n",
        "**Description:** Predict primitves actions in a human demonstration using ConvLSTM model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZFJSlMAbpDhE"
      },
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7gn6YDneJAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0df6a66e-5f4f-4493-9bef-929b1a3de593"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1_bJF4iepDhF",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "import os\n",
        "from glob import glob\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeqMeiJCzxTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_CLASSES  = 2          # no. of primitves in the TADL\n",
        "PX         = 128        # no. of rows in training/test images\n",
        "PY         = 128       # no. of columns in training/test images\n",
        "CHANNELS   = 3          # no. of channels in the image\n",
        "N_FRAMES   = 15         # no. of frames in each training/test video\n",
        "BATCH_SIZE = 32         # size of the batches\n",
        "DATA_DIR   = \"/content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL/\""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkiq6-1Aejkz",
        "colab_type": "text"
      },
      "source": [
        "## Building the Dataset\n",
        "\n",
        "Reads the datafiles and builds the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBiC-UB6bPzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def video_path(dataset_dir):\n",
        "  '''\n",
        "  returns the paths of all video files in the dataset; takes input the parent directory\n",
        "  '''\n",
        "  # no. of primitives in the library\n",
        "  prim_actions    = [dI for dI in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir,dI))]\n",
        "  video_path_list = []\n",
        "  \n",
        "  # building a dictionary of primtive actions for label generation\n",
        "  prim_dict       = {}\n",
        "  i               = 0\n",
        "\n",
        "  for action in prim_actions:\n",
        "    prim_dict[action] = i\n",
        "    prim_path         = os.path.join(DATA_DIR, action)   # gives path for each primitive  \n",
        "    i                 += 1\n",
        "  \n",
        "    for video in os.listdir(prim_path):\n",
        "      video_path  = os.path.join(prim_path, video)        # path to all videos in a prim\n",
        "      video_path_list.append(video_path)\n",
        "      \n",
        "  return video_path_list, prim_dict\n",
        "\n",
        "\n",
        "video_list, primitives_dict = video_path(DATA_DIR)\n",
        "N_CLASSES                   = len(primitives_dict)\n",
        "\n",
        "\n",
        "def build_dataset(vid_list, primit_dict):\n",
        "    '''\n",
        "    This function builds the dataset given the video frames and no of primitives\n",
        "    '''\n",
        "\n",
        "    image_data  = []\n",
        "    label_data  = []\n",
        "\n",
        "    for video_path in vid_list:\n",
        "\n",
        "      label        = video_path.split(os.sep)[-2]\n",
        "      label        = primit_dict[label]\n",
        "      temp_image   = []\n",
        "      temp_label   = []\n",
        "    \n",
        "      for image in os.listdir(video_path):\n",
        "        image_path    = video_path + \"/\" + image \n",
        "      \n",
        "        # taking care of labels\n",
        "        # temp_label.append(label)\n",
        "\n",
        "        # load the raw data from the file as a string\n",
        "        # img = tf.io.read_file(image_path)      \n",
        "        # img = tf.image.decode_jpeg(img, channels=3)\n",
        "        # img = tf.image.resize(img, [PX, PY])\n",
        "        # img = tf.image.convert_image_dtype(img, tf.float32) # Cast and normalize the image to [0,1]\n",
        "        # temp_image.append(img)\n",
        "\n",
        "        img = cv2.imread(image_path, 1)       # image read\n",
        "        img = cv2.resize(img, (PX, PY))       # image resize\n",
        "        # cv2_imshow(img)                     # optional command to visualize the read image\n",
        "        img = img.astype(\"float32\") / 255     # rescale the image from 0-1\n",
        "        temp_image.append(img)\n",
        "\n",
        "      image_data.append(temp_image)\n",
        "      temp_label = label       # temporary\n",
        "      label_data.append(temp_label)\n",
        "\n",
        "    # return image_data, label_data\n",
        "    return  image_data,  tf.one_hot(label_data, len(primit_dict))\n",
        "\n",
        "train_data, train_label = build_dataset(video_list, primitives_dict)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label))\n",
        "\n",
        "## Trying to print the data\n",
        "# for itemx, itemy in dataset.take(3):\n",
        "#   print(itemx.shape, itemy.shape)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cqcT5XrBDMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8910bc41-84ad-4e4f-ddfb-ab5bf3a8da55"
      },
      "source": [
        "test_data = np.asarray(train_data)\n",
        "test_label = np.asarray(train_label)\n",
        "\n",
        "print(test_data.shape)\n",
        "print(test_label.shape)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 15, 128, 128, 3)\n",
            "(2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzI77y_LBjMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f2b76fbc-931f-47f7-e76b-cb19be9fecf1"
      },
      "source": [
        "print(np.shape(train_data))\n",
        "print(train_label)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 15, 128, 128, 3)\n",
            "[0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8gcZ-1lkpDhK"
      },
      "source": [
        "## Build a model\n",
        "\n",
        "We create a model which take as input movies of shape\n",
        "`(n_frames, width, height, channels)` and returns a movie\n",
        "of identical shape.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD19WMc5yPHz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "150db90a-7a97-471c-9008-48d01bbe3d48"
      },
      "source": [
        "print(CHANNELS)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape = (N_FRAMES, PX, PY, CHANNELS)),  \n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=False\n",
        "        ),\n",
        "        # layers.ConvLSTM2D(\n",
        "        #     filters = 64, kernel_size = (3, 3), return_sequences = False, data_format = \"channels_last\", input_shape = (N_FRAMES, PX, PY, 3)\n",
        "        #     ),\n",
        "        # layers.BatchNormalization(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        # layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(N_CLASSES, activation='softmax'),\n",
        "        \n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# model compilation\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(ConvLSTM2D(filters = 64, kernel_size = (3, 3), return_sequences = False, data_format = \"channels_last\", input_shape = (seq_len, img_height, img_width, 3)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(256, activation=\"relu\"))\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(Dense(6, activation = \"softmax\"))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_lst_m2d_8 (ConvLSTM2D)  (None, 128, 128, 64)      154624    \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 1048576)           0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 1048576)           0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2)                 2097154   \n",
            "=================================================================\n",
            "Total params: 2,251,778\n",
            "Trainable params: 2,251,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WBHqG5W_Qou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cadee7d2-40ac-4b9b-e222-2a08cf243a3a"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.ConvLSTM2D(filters = 64, kernel_size = (3, 3), return_sequences = False, data_format = \"channels_last\", input_shape = (N_FRAMES, PX, PY, 3)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(2, activation = \"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_lst_m2d_7 (ConvLSTM2D)  (None, 126, 126, 64)      154624    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 126, 126, 64)      0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1016064)           0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 256)               260112640 \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 260,267,778\n",
            "Trainable params: 260,267,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hM9IeKmypDhV"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-bBV_l6mpDhW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ab7acc98-9fee-4253-b78a-936adb428bad"
      },
      "source": [
        "epochs = 2\n",
        "\n",
        "model.fit(\n",
        "    test_data,\n",
        "    test_label,\n",
        "    batch_size=2,\n",
        "    epochs=epochs,\n",
        "    verbose=2,\n",
        ")\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1/1 - 0s - loss: 0.7667 - accuracy: 0.5000\n",
            "Epoch 2/2\n",
            "1/1 - 0s - loss: 9.2385 - accuracy: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe8b4bfce48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLnCLohPkYO9",
        "colab_type": "text"
      },
      "source": [
        "## Miscellaneous"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bf_VkgzwpDha"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "#### Test the model on one movie\n",
        "\n",
        "Feed it with the first 7 positions and then\n",
        "predict the new positions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y2qaZa3rpDhb",
        "colab": {}
      },
      "source": [
        " movie_index = 1004\n",
        "track = noisy_movies[movie_index][:7, ::, ::, ::]\n",
        "\n",
        "for j in range(16):\n",
        "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
        "    new = new_pos[::, -1, ::, ::, ::]\n",
        "    track = np.concatenate((track, new), axis=0)\n",
        "\n",
        "\n",
        "# And then compare the predictions\n",
        "# to the ground truth\n",
        "track2 = noisy_movies[movie_index][::, ::, ::, ::]\n",
        "for i in range(15):\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "    ax = fig.add_subplot(121)\n",
        "\n",
        "    if i >= 7:\n",
        "        ax.text(1, 3, \"Predictions !\", fontsize=20, color=\"w\")\n",
        "    else:\n",
        "        ax.text(1, 3, \"Initial trajectory\", fontsize=20)\n",
        "\n",
        "    toplot = track[i, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    ax = fig.add_subplot(122)\n",
        "    plt.text(1, 3, \"Ground truth\", fontsize=20)\n",
        "\n",
        "    toplot = track2[i, ::, ::, 0]\n",
        "    if i >= 2:\n",
        "        toplot = shifted_movies[movie_index][i - 1, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    plt.savefig(\"%i_animate.png\" % (i + 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ERnth0tmrLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape = (None, PX, PY, CHANNELS)),  \n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=False\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        \n",
        "        # layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(N_CLASSES, activation='softmax'),\n",
        "        \n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# model compilation\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}