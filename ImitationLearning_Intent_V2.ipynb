{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImitationLearning-Intent-V2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3j__1QFRpDhC"
      },
      "source": [
        "# Primitive Segmentation using ConvLSTM\n",
        "\n",
        "**Author:** Aditya Jain <br>\n",
        "**Date started:** 27th July, 2020<br>\n",
        "**Description:** Predict primitves actions in a human demonstration using ConvLSTM model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZFJSlMAbpDhE"
      },
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7gn6YDneJAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1_bJF4iepDhF",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "import os\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeqMeiJCzxTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_CLASSES  = 2          # no. of primitves in the TADL\n",
        "PX         = 256        # no. of rows in training/test images\n",
        "PY         = 256        # no. of columns in training/test images\n",
        "CHANNELS   = 3          # no. of channels in the image\n",
        "N_FRAMES   = 15         # no. of frames in each training/test video\n",
        "BATCH_SIZE = 32         # size of the batches\n",
        "DATA_DIR   = \"/content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkiq6-1Aejkz",
        "colab_type": "text"
      },
      "source": [
        "## Building the Dataset\n",
        "\n",
        "Reads the datafiles and builds the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBiC-UB6bPzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def video_path(dataset_dir):\n",
        "  '''\n",
        "  returns the paths of all video files in the dataset; takes input the parent directory\n",
        "  '''\n",
        "  # no. of primitives in the library\n",
        "  prim_actions    = [dI for dI in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir,dI))]\n",
        "\n",
        "  video_path_list = []\n",
        "\n",
        "  for action in prim_actions:\n",
        "    prim_path     = os.path.join(DATA_DIR, action)      # gives path for each primitive  \n",
        "  \n",
        "    for video in os.listdir(prim_path):\n",
        "      video_path  = os.path.join(prim_path, video)      # path to all videos in a prim\n",
        "      video_path_list.append(video_path)\n",
        "      \n",
        "  return video_path_list\n",
        "\n",
        "\n",
        "video_list = video_path(DATA_DIR)\n",
        "\n",
        "\n",
        "# this function builds the dataset\n",
        "def build_dataset(vid_list):\n",
        "\n",
        "    image_data  = []\n",
        "    label_data  = []\n",
        "\n",
        "    for video_path in vid_list:\n",
        "\n",
        "      label        = tf.strings.split(video_path, os.sep)[-2]\n",
        "      temp_image   = []\n",
        "      temp_label   = []\n",
        "    \n",
        "      for image in os.listdir(video_path):\n",
        "        image_path    = video_path + \"/\" + image \n",
        "      \n",
        "        # taking care of labels\n",
        "        temp_label.append(label)\n",
        "\n",
        "        # load the raw data from the file as a string\n",
        "        img = tf.io.read_file(image_path)      \n",
        "        img = tf.image.decode_jpeg(img, channels=3)\n",
        "        img = tf.image.resize(img, [PX, PY])\n",
        "        img = tf.image.convert_image_dtype(img, tf.float32) # Cast and normalize the image to [0,1]\n",
        "        temp_image.append(img)\n",
        "\n",
        "      image_data.append(temp_image)\n",
        "      label_data.append(temp_label)\n",
        "\n",
        "    return  image_data,  label_data\n",
        "\n",
        "train_data, train_label = build_dataset(video_list)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label))\n",
        "\n",
        "## Trying to print the data\n",
        "# for itemx, itemy in dataset.take(3):\n",
        "#   print(itemy.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8gcZ-1lkpDhK"
      },
      "source": [
        "## Build a model\n",
        "\n",
        "We create a model which take as input movies of shape\n",
        "`(n_frames, width, height, channels)` and returns a movie\n",
        "of identical shape.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD19WMc5yPHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape = (None, PX, PY, CHANNELS)),  \n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        # layers.Flatten(),\n",
        "        layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(N_CLASSES, activation='softmax'),\n",
        "        \n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# model compilation\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hM9IeKmypDhV"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-bBV_l6mpDhW",
        "colab": {}
      },
      "source": [
        "epochs = 2\n",
        "\n",
        "model.fit(\n",
        "    image_data,\n",
        "    batch_size=10,\n",
        "    epochs=epochs,\n",
        "    verbose=2,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bf_VkgzwpDha"
      },
      "source": [
        "## Test the model on one movie\n",
        "\n",
        "Feed it with the first 7 positions and then\n",
        "predict the new positions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y2qaZa3rpDhb",
        "colab": {}
      },
      "source": [
        " movie_index = 1004\n",
        "track = noisy_movies[movie_index][:7, ::, ::, ::]\n",
        "\n",
        "for j in range(16):\n",
        "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
        "    new = new_pos[::, -1, ::, ::, ::]\n",
        "    track = np.concatenate((track, new), axis=0)\n",
        "\n",
        "\n",
        "# And then compare the predictions\n",
        "# to the ground truth\n",
        "track2 = noisy_movies[movie_index][::, ::, ::, ::]\n",
        "for i in range(15):\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "    ax = fig.add_subplot(121)\n",
        "\n",
        "    if i >= 7:\n",
        "        ax.text(1, 3, \"Predictions !\", fontsize=20, color=\"w\")\n",
        "    else:\n",
        "        ax.text(1, 3, \"Initial trajectory\", fontsize=20)\n",
        "\n",
        "    toplot = track[i, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    ax = fig.add_subplot(122)\n",
        "    plt.text(1, 3, \"Ground truth\", fontsize=20)\n",
        "\n",
        "    toplot = track2[i, ::, ::, 0]\n",
        "    if i >= 2:\n",
        "        toplot = shifted_movies[movie_index][i - 1, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    plt.savefig(\"%i_animate.png\" % (i + 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}